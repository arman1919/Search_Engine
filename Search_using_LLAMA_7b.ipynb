{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f27504e8",
   "metadata": {},
   "source": [
    "# Finding a product by description using LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131e0803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b0a496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  A function to extract the response as a list of identifiers from the LLM response\n",
    "\n",
    "\n",
    "def extract_list(text):\n",
    "    pattern = r\"\\[(\\d+(?:,\\s*\\d+)*)\\]\"\n",
    "\n",
    "    matches = re.findall(pattern, text)\n",
    "\n",
    "    if matches:\n",
    "        extracted_list = [int(num) for num in matches[0].split(\",\")]\n",
    "        return extracted_list\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cad78e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numbering the list of products\n",
    "\n",
    "def enumerate_list(products):\n",
    "    for i, product in enumerate(products, start=1):\n",
    "        product[\"ID\"] = i\n",
    "        new_product = {\"ID\": product[\"ID\"]}\n",
    "        new_product.update(product)\n",
    "        products[i-1] = new_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec964bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# String representation of the dictionary list\n",
    "\n",
    "def dicts_to_str(products):\n",
    "    prods = \"\"\n",
    "\n",
    "    for product in products[:-1]:\n",
    "        prods +=\"ID:\" + str(product[\"ID\"]) + \" \"\n",
    "        prods +=\"Name:\" +  product[\"Name\"] + \" \"\n",
    "        prods +=\"Description:\"+ product[\"Description\"] + \" \"\n",
    "        prods +=\"Applications:\" + \", \".join(product[\"APPLICATIONS\"]) + \" \"\n",
    "        prods +=\"Product Categories:\" + \", \".join(product[\"PRODUCT CATEGORIES\"]) + \" \"\n",
    "        prods +=\"Target Industries:\" + \", \".join(product[\"TARGET INDUSTRIES\"]) + \" \"\n",
    "        prods +=\"\\n\"\n",
    "    \n",
    "    prods +=\"ID:\" + str(products[-1][\"ID\"]) + \" \"\n",
    "    prods +=\"Name:\" +  products[-1][\"Name\"] + \" \"\n",
    "    prods +=\"Description:\"+ products[-1][\"Description\"] + \" \"\n",
    "    prods +=\"Applications:\" + \", \".join(products[-1][\"APPLICATIONS\"]) + \" \"\n",
    "    prods +=\"Product Categories:\" + \", \".join(products[-1][\"PRODUCT CATEGORIES\"]) + \" \"\n",
    "    prods +=\"Target Industries:\" + \", \".join(products[-1][\"TARGET INDUSTRIES\"]) + \" \"\n",
    "     \n",
    "    return  prods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b58751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a database for product search\n",
    "\n",
    "def creat_db(products):\n",
    "    enumerate_list(products)\n",
    "     \n",
    "    return dicts_to_str(products)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e286c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"products_DB_(EN).json\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "products = creat_db(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1c5cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a model and creating a pipeline\n",
    "\n",
    "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "pipeline = transformers.pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model_id,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d25e9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a prompt\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": f\"You are a useful assistant in the search. Your task is to find the names of the products from the list \\n{products}} \\n that correspond to user content, return a python list containing the product IDs that correspond to user content, output without explanation, if you can't find corresponding product return 'Not found', \\n example: [1,2,3,...,n] \"},\n",
    "    {\"role\": \"user\", \"content\": \"I need a device used for heat measurements.\"},\n",
    "]\n",
    "\n",
    "prompt = pipeline.tokenizer.apply_chat_template(\n",
    "        messages, \n",
    "        tokenize=False, \n",
    "        add_generation_prompt=True\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    pipeline.tokenizer.eos_token_id,\n",
    "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae85576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding a product\n",
    "\n",
    "outputs = pipeline(\n",
    "    prompt,\n",
    "    max_new_tokens=500,\n",
    "    eos_token_id=terminators,\n",
    "    do_sample=True,\n",
    "    temperature=0.2,\n",
    "    top_p=0.9,\n",
    "    pad_token_id=pipeline.tokenizer.eos_token_id\n",
    ")\n",
    "\n",
    "answer = outputs[0][\"generated_text\"][len(prompt):]\n",
    "\n",
    "Product_IDs = extract_list(answer)\n",
    "\n",
    "print(f\"Found products: {Product_IDs}\")\n",
    "print(f\"LLM answer {answer}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se_llm",
   "language": "python",
   "name": "se_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
